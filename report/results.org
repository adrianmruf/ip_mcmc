* Results
** Analytic sampling from a bimodal Gaussian
*** Setup

    Attempting to recreate the "Computational Illustration" from [[cite:cotter_mcmc_2013]]. They use,
    among other algorithms, pCN to sample from a 1-D bimodal Gaussian
    $$\rho \propto (\N{3}{1} + \N{-3}{1}) \mathds{1}_{[-10,10]}.$$
    Since the density estimation framework for a known distribution is not quite clear to me from
    the paper, I don't expect to perfectly replicate their results.

    They use a formulation of the prior based on the Karhunen-LoÃ©ve Expansion that doesn't make
    sense to me in the 1-D setting (how do I sum infinite eigenfunctions of a scalar?).

    The potential for density estimation described in section is also not clear to me (maybe for
    a similar reason? What is $u$ in the density estimate case?).

    I ended up using a normal $\N{0}{1}$ as a prior and the potential described [[Potential for Bayes'-MCMC when sampling from analytic distributions][before]], and
    compared the following samplers:
    - (1) [[file:code.org::StandardRWProposer][~StandardRWProposer~]] ($\delta=0.25$) + [[file:code.org::AnalyticAccepter][~AnalyticAccepter~]]
    - (2) [[file:code.org::StandardRWProposer][~StandardRWProposer~]] ($\delta=0.25$) + [[file:code.org::StandardRWAccepter][~StandardRWAccepter~]]
    - (3) [[file:code.org::pCNProposer][~pCNProposer~]] ($\beta=0.25$) + [[file:code.org::pCNAccepter][~pCNAccepter~]]

    The code is in [[file:scripts/analytic.py][~analytic.py~]].

*** Result

    All three samplers are able to reproduce the target density [[fig:hist_bimodal]]

    #+CAPTION: Burn-in: 1000, sample-interval: 200, samples: 500
    #+NAME: fig:hist_bimodal
    [[./figures/bimodal_density_combined.png]]

    The autocorrelation decays for all samplers: [[fig:ac_bimodal]]. However, the pCN doens't
    do nearly as well as expected. This could be the consequence of the awkward
    formulation of the potential or a bad prior.

    #+CAPTION: AC of bimodal distribution. pCN takes forever to decorrelate
    #+NAME: fig:ac_bimodal
    [[./figures/analytic_standard_rw_pCN_50_5000.png]]

** Bayesian inverse problem for $\G{u} = \langle g,u \rangle$
   For $\G{u} = \langle g,u \rangle$ the resulting posterior under a Gaussian prior
   is again a Gaussian. The model equation is
   $$y = \G{u} + \eta$$
   with:
   - $y \in \R$
   - $u \in \R^n$
   - $\eta \sim \N{0}{\gamma^2}$ for $\gamma \in \R$

   A concrete realization with scalar $u$:
   - $u = 2$
   - $g = 3$
   - $\gamma = 0.5$
   - $y=6.172$
   - prior $\N{0}{\Sigma_0=1}$
   leads to a posterior with mean
   $\mu = \frac{(\Sigma_0g)y}{\gamma^2 + \langle g, \Sigma_0g \rangle} \approx 2$,
   which is what we see when we plot the result [[fig:stuart_21_density]].
   The pCN-Sampler with $\beta = 0.25$ had an acceptance rate of 0.567.
    
   #+CAPTION: $N=5000, \mu \approx 2$
   #+NAME: fig:stuart_21_density
   [[./figures/stuart_example_21_n=1_N=5000.png]]

   For $n>2$, the resulting posterior can not be plotted anymore. However, it is still Gaussian
   with given mean & covariance. Can just compare the analytical values to the sample values.
   Verify that the error decays like $\frac{1}{\sqrt{N}}$.
** Bayesian inverse problem for $\G{u} = g (u + \beta u^3)$
   Since the observation operator is not linear anymore, the resulting posterior is not
   Gaussian in general. However, since the dimension of the input $u$ is 1, it can
   still be plotted.

   The concrete realization with:
   - $g = [3, 1]$
   - $u = 0.5$
   - $\beta = 0$
   - $y= [1.672, 0.91]$
   - $\gamma = 0.5$
   - $\eta \sim \N{0}{\gamma^2 I}$
   - prior $\N{0}{\Sigma_0=1}$
   however leads to a Gaussian thanks to $\beta = 0$. The mean is
   $\mu = \frac{\langle g,y \rangle}{\gamma^2 + |g|^2} \approx 0.58$. Plot: [[fig:stuart_22_density]]

   The pCN-Sampler with $\beta = 0.25$ (different beta) had an acceptance rate of 0.576.

   #+CAPTION: $N=5000, \mu \approx 0.58$
   #+NAME: fig:stuart_22_density
   [[./figures/stuart_example_22_q=2_N=5000.png]]

   For $\beta \neq 0$, the resulting posterior is not a Gaussian. Still $n=1$, so it can be
   plotted. Just numerically normalize the analytical expression of the posterior?

** Lorenz96 model
   #+INCLUDE: lorenz.org
** Perturbed Riemann problem for Burgers' equation
   #+INCLUDE: burgers.org
