* Results
** Analytic sampling from a bimodal Gaussian
*** Setup

    Attempting to recreate the "Computational Illustration" from [[cite:cotter_mcmc_2013]]. They use,
    among other algorithms, pCN to sample from a 1-D bimodal Gaussian
    $$\rho \propto (\N{3}{1} + \N{-3}{1}) \mathds{1}_{[-10,10]}.$$
    Since the density estimation framework for a known distribution is not quite clear to me from
    the paper, I don't expect to perfectly replicate their results.

    They use a formulation of the prior based on the Karhunen-Loéve Expansion that doesn't make
    sense to me in the 1-D setting (how do I sum infinite eigenfunctions of a scalar?).

    The potential for density estimation described in section is also not clear to me (maybe for
    a similar reason? What is $u$ in the density estimate case?).

    I ended up using a normal $\N{0}{1}$ as a prior and the potential described [[Potential for Bayes'-MCMC when sampling from analytic distributions][before]], and
    compared the following samplers:
    - (1) [[file:code.org::StandardRWProposer][~StandardRWProposer~]] ($\delta=0.25$) + [[file:code.org::AnalyticAccepter][~AnalyticAccepter~]]
    - (2) [[file:code.org::StandardRWProposer][~StandardRWProposer~]] ($\delta=0.25$) + [[file:code.org::StandardRWAccepter][~StandardRWAccepter~]]
    - (3) [[file:code.org::pCNProposer][~pCNProposer~]] ($\beta=0.25$) + [[file:code.org::pCNAccepter][~pCNAccepter~]]

    The code is in [[file:scripts/analytic.py][~analytic.py~]].

*** Result

    All three samplers are able to reproduce the target density [[fig:hist_bimodal]]

    #+CAPTION: Burn-in: 1000, sample-interval: 200, samples: 500
    #+NAME: fig:hist_bimodal
    [[./figures/bimodal_density_combined.png]]

    The autocorrelation decays for all samplers: [[fig:ac_bimodal]]. However, the pCN doens't
    do nearly as well as expected. This could be the consequence of the awkward
    formulation of the potential or a bad prior.

    #+CAPTION: AC of bimodal distribution. pCN takes forever to decorrelate
    #+NAME: fig:ac_bimodal
    [[./figures/analytic_standard_rw_pCN_50_5000.png]]


** Bayesian inverse problem for $\G{u} = \langle g,u \rangle$
   For $\G{u} = \langle g,u \rangle$ the resulting posterior under a Gaussian prior
   is again a Gaussian. The model equation is
   $$y = \G{u} + \eta$$
   with:
   - $y \in \R$
   - $u \in \R^n$
   - $\eta \sim \N{0}{\gamma^2}$ for $\gamma \in \R$

   A concrete realization with scalar $u$:
   - $u = 2$
   - $g = 3$
   - $\gamma = 0.5$
   - $y=6.172$
   - prior $\N{0}{\Sigma_0=1}$
   leads to a posterior with mean
   $\mu = \frac{(\Sigma_0g)y}{\gamma^2 + \langle g, \Sigma_0g \rangle} \approx 2$,
   which is what we see when we plot the result [[fig:stuart_21_density]].
   The pCN-Sampler with $\beta = 0.25$ had an acceptance rate of 0.567.
    
   #+CAPTION: $N=5000, \mu \approx 2$
   #+NAME: fig:stuart_21_density
   [[./figures/stuart_example_21_n=1_N=5000.png]]

   For $n>2$, the resulting posterior can not be plotted anymore. However, it is still Gaussian
   with given mean & covariance. Can just compare the analytical values to the sample values.
   Verify that the error decays like $\frac{1}{\sqrt{N}}$.
** Bayesian inverse problem for $\G{u} = g (u + \beta u^3)$
   Since the observation operator is not linear anymore, the resulting posterior is not
   Gaussian in general. However, since the dimension of the input $u$ is 1, it can
   still be plotted.

   The concrete realization with:
   - $g = [3, 1]$
   - $u = 0.5$
   - $\beta = 0$
   - $y= [1.672, 0.91]$
   - $\gamma = 0.5$
   - $\eta \sim \N{0}{\gamma^2 I}$
   - prior $\N{0}{\Sigma_0=1}$
   however leads to a Gaussian thanks to $\beta = 0$. The mean is
   $\mu = \frac{\langle g,y \rangle}{\gamma^2 + |g|^2} \approx 0.58$. Plot: [[fig:stuart_22_density]]

   The pCN-Sampler with $\beta = 0.25$ (different beta) had an acceptance rate of 0.576.

   #+CAPTION: $N=5000, \mu \approx 0.58$
   #+NAME: fig:stuart_22_density
   [[./figures/stuart_example_22_q=2_N=5000.png]]

   For $\beta \neq 0$, the resulting posterior is not a Gaussian. Still $n=1$, so it can be
   plotted. Just numerically normalize the analytical expression of the posterior?
** Geophysics example: Lorenz-96 model

*** Based on:

    Lorenz, E. N. (1996). Predictability—A problem partly solved. In Reprinted in T. N. Palmer & R. Hagedorn (Eds.), Proceedings Seminar on
    Predictability, Predictability of Weather and Climate, Cambridge UP (2006) (Vol. 1, pp. 1–18). Reading, Berkshire, UK: ECMWF.

*** Equation

    A system of ODEs, representing the coupling between slow variables $X$ and fast, subgrid
    variables $Y$.

    $$ \dv{X_k}{t} =                 - X_{k-1}(X_{k-2} - X_{k+1}) - X_k + F - hc \bar{Y}_k $$
    $$ \frac{1}{c} \dv{Y_{j,k}}{t} = -bY_{j+1,k}(Y_{j+2,k} - Y_{j-1, k}) - Y_{j,k} + \frac{h}{J}X_k$$

    - $X = [X_0, ..., X_{K-1}] \in \R^K$
    - $Y = [Y_{j, 0} | ... | Y_{j, K-1}] \in \R^{J \cross K}$ \\
      $Y_{j,k} = [Y_{0,k}, ..., Y_{J-1,k}] \in  \R^J$
    - $\bar{Y}_k = \frac{1}{J}\sum_j Y_{j,k}$
    - periodic: $X_K = X_0$, $Y_{J,k} = Y_{0,k}$
    - Parameters $\Theta = [F, h, c, b]$
    - $h$: coupling strength
    - $c$: relative damping
    - $F$: external forcing of the slow variables (large scale forcing)
    - $b$: scale of non-linear interaction of fast variables
    - $t = 1 \Leftrightarrow 1$ day (simulation duration is given in days)

*** Properties

    - For $K=36$, $J=10$ and $\Theta = [F, h, c, b] = [10, 1, 10, 10]$ there is chaotic behaviour.

    - The nonlinearities conserve the energies within a subsystem: (show!)
      - $E_X = \sum_k X_k^2$
      - $E_{Y_k} = \sum_j Y_{j,k}^2$

    - The interaction conserves the total energy: (show!)
      - $E_{T} = \sum_k (X_k^2 + \sum_j Y_{j,k}^2)$

    - In the statistical steady state, the external forcing $F$ (as long as its positive) balances
      the dampling of the linear terms.

    - Averaged quantities
      - $\expval{\phi} = \frac{1}{T} \int_{t_0}^{t_0 + T} \phi(t) \dd{t}$ (or a sum over discrete values)
      - Long-term time-mean in the statistical steady state: $\expval{\cdot}_{\infty}$
      - $\expval{X^2}_\infty = F \expval{X}_{\infty} - hc \expval{X\bar{Y}}_\infty$ $\forall k$ \\
        (multiply $X$ -equation by $X$, all $X_k$ s are statistically equivalent, $\dv{X}{t} = 0$ in steady state)
      - $\expval{\bar{Y^2}}_{\infty} = \frac{h}{J} \expval{X \bar{Y}}_{\infty}$
